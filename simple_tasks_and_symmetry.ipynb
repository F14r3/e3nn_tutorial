{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Tasks and Symmetry\n",
    "There are some unintuitive consequences of using E(3) equivariant neural networks. The symmetry your output has to be equal to or higher than the symmetry of your input. The following 3 simple tasks are to help demonstrate this:\n",
    "* Task 1: Distort a rectangle to a square.\n",
    "* Task 2: Distort a square to a rectangle.\n",
    "* Task 3: Distort a square to a rectangle -- with symmetry breaking.\n",
    "\n",
    "We will see that we can quickly do Task 1, but not Task 2. Only by using symmetry breaking in Task 3 are we able to distort a square into a rectangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "import se3cnn\n",
    "from se3cnn.point.operations import Convolution\n",
    "from se3cnn.non_linearities import GatedBlock\n",
    "from se3cnn.point.kernel import Kernel\n",
    "from se3cnn.point.radial import CosineBasisModel\n",
    "from se3cnn.non_linearities import rescaled_act\n",
    "\n",
    "from spherical import SphericalTensor\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these tasks, we want to move 4 points in one configuration to another configuration. The input to the network will be the initial geometry and features on that geometry. The output will be used to signify \"displacement\" of each point to the new configuration. We can represent displacement in a couple different ways. The simplest way is to represent a displacement as an L=1 vector, `Rs=[(1, 1]]`. However, to better illustrate the symmetry properties of the network, we instead are going to use a spherical harmonic signal or more specifically, the peak of the spherical harmonic signal, to signify the displacement of the original point.\n",
    "\n",
    "First, we set up a very basic network that has the same representation list `Rs = [(1, L) for L in range(5 + 1)]` throughout the entire network. The input will be a spherical tensor with representation `Rs` and the output will also be a spherical tensor with representation `Rs`. We will interpret the output of the network as a spherical harmonic signal where the peak location will signify the desired displacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self, Rs, n_layers=3, sh=None, max_radius=3.0, number_of_basis=3, radial_layers=3):\n",
    "        super().__init__()\n",
    "        self.Rs = Rs\n",
    "        self.n_layers = n_layers\n",
    "        self.L_max = max(L for m,L in Rs)\n",
    "        \n",
    "        sp = rescaled_act.Softplus(beta=5)\n",
    "         \n",
    "        Rs_geo = [(1, l) for l in range(self.L_max + 1)]\n",
    "        Rs_centers = [(1, 0), (1, 1)]\n",
    "        \n",
    "        RadialModel = partial(CosineBasisModel, max_radius=max_radius,\n",
    "                              number_of_basis=number_of_basis, h=100,\n",
    "                              L=radial_layers, act=sp)\n",
    "\n",
    "        \n",
    "        K = partial(Kernel, RadialModel=RadialModel, sh=sh)\n",
    "        C = partial(Convolution, K)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList([\n",
    "            GatedBlock(Rs, Rs, sp, rescaled_act.sigmoid, C)\n",
    "            for i in range(n_layers - 1)\n",
    "        ])\n",
    "\n",
    "        self.layers.append(\n",
    "            Convolution(K, Rs, Rs) \n",
    "        )\n",
    "\n",
    "    def forward(self, input, geometry):\n",
    "        output = input\n",
    "        batch, N, _ = geometry.shape\n",
    "        for layer in self.layers:\n",
    "            output = layer(output.div(N ** 0.5), geometry)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Distort a rectangle to square.\n",
    "In this task, our input is a four points in the shape of a rectangle with simple scalars (1.0) at each point. The task is to learn to displace the points to form a (more symmetric) square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square = torch.tensor(\n",
    "    [[0., 0., 0.], [1., 0., 0.], [1., 1., 0.], [0., 1., 0.]]\n",
    ")\n",
    "square -= square.mean(-2)\n",
    "rectangle = square * torch.tensor([0.5, 1.5, 0.])\n",
    "rectangle -= rectangle.mean(-2)\n",
    "\n",
    "N, _ = square.shape\n",
    "\n",
    "L_max = 5\n",
    "Rs = [(1, L) for L in range(L_max + 1)]\n",
    "\n",
    "model = Network(Rs)\n",
    "\n",
    "params = model.parameters()\n",
    "optimizer = torch.optim.Adam(params, 1e-3)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.zeros(1, N, sum(2 * L + 1 for L in range(L_max + 1)))\n",
    "input[:, :, 0] = 1.  # batch, point, channel\n",
    "\n",
    "displacements = square - rectangle\n",
    "N, _ = displacements.shape\n",
    "projections = torch.stack([SphericalTensor.from_geometry(displacements[i], L_max).signal for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "for i in range(iterations):\n",
    "    output = model(input, rectangle.unsqueeze(0))\n",
    "    loss = loss_fn(output, projections.unsqueeze(0))\n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spherical harmonic projections\n",
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 1, 1\n",
    "specs = [[{'is_3d': True} for i in range(cols)]\n",
    "         for j in range(rows)]\n",
    "fig = make_subplots(rows=rows, cols=cols, specs=specs)\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=rectangle[:, 0], y=rectangle[:, 1], z=rectangle[:, 2], mode=\"markers\", name=\"Rectangle\"))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=square[:, 0], y=square[:, 1], z=square[:, 2], mode=\"markers\", name=\"Square\"))\n",
    "\n",
    "for i in range(N):\n",
    "    trace = SphericalTensor(output[0][i].detach(), Rs).plot(center=rectangle[i])\n",
    "    trace.showscale = False\n",
    "    fig.add_trace(trace, 1, 1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Now the reverse! Distort a square to rectangle.\n",
    "In this task, our input is a four points in the shape of a square with simple scalars (1.0) at each point. The task is to learn to displace the points to form a (less symmetric) rectangle. Can the network learn this task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(Rs)\n",
    "\n",
    "params = model.parameters()\n",
    "optimizer = torch.optim.Adam(params, 1e-3)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.zeros(1, N, sum(2 * L + 1 for L in range(L_max + 1)))\n",
    "input[:, :, 0] = 1.  # batch, point, channel\n",
    "\n",
    "\n",
    "\n",
    "displacements = rectangle - square\n",
    "N, _ = displacements.shape\n",
    "projections = torch.stack([SphericalTensor.from_geometry(displacements[i], L_max).signal for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "for i in range(iterations):\n",
    "    output = model(input, square.unsqueeze(0))\n",
    "    loss = loss_fn(output, projections.unsqueeze(0))\n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hmm... seems to get stuck. Let's try more iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "for i in range(iterations):\n",
    "    output = model(input, square.unsqueeze(0))\n",
    "    loss = loss_fn(output, projections.unsqueeze(0))\n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's stuck. What's going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 1, 1\n",
    "specs = [[{'is_3d': True} for i in range(cols)]\n",
    "         for j in range(rows)]\n",
    "fig = make_subplots(rows=rows, cols=cols, specs=specs)\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=rectangle[:, 0], y=rectangle[:, 1], z=rectangle[:, 2], mode=\"markers\", name=\"Rectangle\"))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=square[:, 0], y=square[:, 1], z=square[:, 2], mode=\"markers\", name=\"Square\"))\n",
    "\n",
    "for i in range(N):\n",
    "    trace = SphericalTensor(output[0][i].detach(), Rs).plot(center=square[i])\n",
    "    trace.showscale = False\n",
    "    fig.add_trace(trace, 1, 1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The symmetry of the output must be higher or equal to the symmetry of the input! \n",
    "To be able to do this task, you need to give the network more information -- information that breaks the symmetry to that of the desired output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Fixing Task 2. Distort a square into a rectangle -- now, with symmetry breaking!\n",
    "In this task, our input is a four points in the shape of a square with simple scalars (1.0) AND a contribution for the $x^2 - y^2$ feature at each point. The task is to learn to displace the points to form a (less symmetric) rectangle. Can the network learn this task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(Rs)\n",
    "\n",
    "params = model.parameters()\n",
    "optimizer = torch.optim.Adam(params, 1e-3)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.zeros(1, N, sum(2 * L + 1 for L in range(L_max + 1)))\n",
    "input[:, :, 0] = 1.  # batch, point, channel\n",
    "# Breaking x and y symmetry with x^2 - y^2 component\n",
    "input[:, :, 8] = 0.1  # x^2 - y^2\n",
    "\n",
    "displacements = rectangle - square\n",
    "N, _ = displacements.shape\n",
    "projections = torch.stack([SphericalTensor.from_geometry(displacements[i], L_max).signal for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "for i in range(iterations):\n",
    "    output = model(input, square.unsqueeze(0))\n",
    "    loss = loss_fn(output, projections.unsqueeze(0))\n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 1, 1\n",
    "specs = [[{'is_3d': True} for i in range(cols)]\n",
    "         for j in range(rows)]\n",
    "fig = make_subplots(rows=rows, cols=cols, specs=specs)\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=rectangle[:, 0], y=rectangle[:, 1], z=rectangle[:, 2], mode=\"markers\", name=\"Rectangle\"))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=square[:, 0], y=square[:, 1], z=square[:, 2], mode=\"markers\", name=\"Square\"))\n",
    "\n",
    "for i in range(N):\n",
    "    trace = SphericalTensor(output[0][i].detach(), Rs).plot(center=square[i])\n",
    "    trace.showscale = False\n",
    "    fig.add_trace(trace, 1, 1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is $x^2 - y^2$ the term doing? It's breaking the symmetry along the $\\hat{x}$ and $\\hat{y}$ directions.\n",
    "Notice how the shape below is an ellisoid elongated in the y direction and squished in the x. This isn't the only pertubation we could've added, but it is the most symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 1, 1\n",
    "specs = [[{'is_3d': True} for i in range(cols)]\n",
    "         for j in range(rows)]\n",
    "fig = make_subplots(rows=rows, cols=cols, specs=specs)\n",
    "\n",
    "L_max = 5\n",
    "Rs = [(1, L) for L in range(L_max + 1)]\n",
    "sum_Ls = sum(2 * L + 1 for mult, L in Rs) \n",
    "\n",
    "# Random spherical tensor up to L_Max\n",
    "signal = torch.zeros(sum_Ls)\n",
    "signal[0] = 1\n",
    "# Breaking x and y symmetry with x^2 - y^2\n",
    "signal[8] = -0.1\n",
    "\n",
    "sphten = SphericalTensor(signal, Rs)\n",
    "\n",
    "trace = sphten.plot(relu=False, n=60)\n",
    "fig.add_trace(trace, row=1, col=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
